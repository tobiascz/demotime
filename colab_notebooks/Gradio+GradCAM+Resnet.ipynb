{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gradio+GradCAM+Resnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMuP56KwAr1orV74lg2ItgH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chcomet/CAP-CS4MS/blob/main/Gradio%2BGradCAM%2BResnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resnet 18"
      ],
      "metadata": {
        "id": "K8emWkmbsSYv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vALr0SEKsB7P"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models, transforms\n",
        "import numpy as np\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper parameter for model\n",
        "classes = ['cat', 'dog']\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "ZIL4QzvTt_gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# image transforms\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "tf = transforms.Compose([transforms.Resize((224, 224)),\n",
        "              transforms.ToTensor(),\n",
        "              transforms.Normalize(mean=mean, std=std)])\n",
        "# convert normalized tensor to numpy array\n",
        "def tensor2np(tensor, mean, std):\n",
        "  # inverse of normalization\n",
        "  tensor = tensor.clone()\n",
        "  mean_tensor = torch.as_tensor(list(mean), dtype=tensor.dtype, device=tensor.device).view(-1,1,1)\n",
        "  std_tensor = torch.as_tensor(list(std), dtype=tensor.dtype, device=tensor.device).view(-1,1,1)\n",
        "  tensor.mul_(std_tensor).add_(mean_tensor)\n",
        "  # convert tensor to numpy format for plt presentation\n",
        "  npimg = tensor.numpy()\n",
        "  npimg = np.transpose(npimg,(1,2,0)) # C*H*W => H*W*C\n",
        "  return npimg"
      ],
      "metadata": {
        "id": "ci43zp6T8hoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set up resnet18\n",
        "model = models.resnet18(pretrained=False)\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(512,256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(256,2),\n",
        "    nn.LogSoftmax(dim=1)\n",
        ")\n",
        "state_dict_train = torch.hub.load_state_dict_from_url('https://github.com/CS4MS/CS4MS_W21/raw/main/checkpoints/dogs-vs-cats.pth', map_location=device)\n",
        "# load the trained weights (state_dict) in our model\n",
        "model.load_state_dict(state_dict_train[\"state_dict\"])\n",
        "# put our model in eval mode\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "QXdYvUolzsXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grad CAM"
      ],
      "metadata": {
        "id": "H_yGn_khsVcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone repository\n",
        "!git clone https://github.com/jacobgil/pytorch-grad-cam.git\n",
        "# install the related dependencies\n",
        "!pip install -r /content/pytorch-grad-cam/requirements.txt\n",
        "# move the core module to working directory /content\n",
        "!mv /content/pytorch-grad-cam/pytorch_grad_cam /content/pytorch_grad_cam"
      ],
      "metadata": {
        "id": "RmKgZx_K05Ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image"
      ],
      "metadata": {
        "id": "SRwGQEQ20pGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# draw Grad-CAM on image \n",
        "def image_grad_cam(model, input_tensor, input_float_np, target_layers):\n",
        "  cam = GradCAM(model=model, target_layers=target_layers, use_cuda=False)\n",
        "  grayscale_cam = cam(input_tensor=input_tensor)\n",
        "  grayscale_cam = grayscale_cam[0, :]\n",
        "  return show_cam_on_image(input_float_np, grayscale_cam, use_rgb=True)"
      ],
      "metadata": {
        "id": "NpPxs5cPK2LM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradio"
      ],
      "metadata": {
        "id": "Ha1HH-LysX7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "1bXFOT-SJFxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# config the predict function, input type of image is numpy.nparray\n",
        "def predict(inp):\n",
        "  # numpy.nparray -> PIL.Image\n",
        "  img = Image.fromarray(inp.astype('uint8'), 'RGB')\n",
        "  # normalize the image to fit the input size of our model\n",
        "  input_tensor = tf(img)\n",
        "  # get copyt of input in type of numpy array float32\n",
        "  input_float_np = tensor2np(input_tensor, mean, std)\n",
        "  # unsqueeze the input_tensor\n",
        "  input_tensor = input_tensor.unsqueeze(dim=0)\n",
        "  # predict\n",
        "  with torch.no_grad():\n",
        "    outputs = model(input_tensor)\n",
        "  outputs = torch.exp(outputs)\n",
        "  # probabilities of all classes\n",
        "  pred_softmax = torch.softmax(outputs, dim=1).cpu().numpy()[0]\n",
        "  # grad_cam image\n",
        "  target_layers = [model.layer4[-1]]\n",
        "  output_img = image_grad_cam(model,input_tensor,input_float_np,target_layers)\n",
        "  # return label dict and suggestion\n",
        "  return {classes[i]: float(pred_softmax[i]) for i in range(len(classes))},output_img"
      ],
      "metadata": {
        "id": "02OMNwA5I_tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download sample images\n",
        "!wget https://cdn.pixabay.com/photo/2014/11/30/14/11/cat-551554_960_720.jpg\n",
        "!mv /content/cat-551554_960_720.jpg /content/cat.jpg\n",
        "!wget https://cdn.pixabay.com/photo/2015/11/17/13/13/bulldog-1047518_960_720.jpg\n",
        "!mv /content/bulldog-1047518_960_720.jpg /content/bulldog.jpg"
      ],
      "metadata": {
        "id": "GQvzipwCAO6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start gradio application\n",
        "gr.Interface(\n",
        "        fn=predict, \n",
        "        inputs=gr.inputs.Image(), \n",
        "        outputs=[gr.outputs.Label(label=\"Classification Result\"),gr.outputs.Image(label=\"GRADCAM\")],\n",
        "        examples=[['cat.jpg'],['bulldog.jpg']],\n",
        "        title=\"Cat and Dog Classification\"\n",
        "      ).launch()"
      ],
      "metadata": {
        "id": "sE0K_jydJPqB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}